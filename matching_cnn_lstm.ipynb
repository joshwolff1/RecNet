{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matching_cnn_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7lchdAN5rFO",
        "colab_type": "text"
      },
      "source": [
        "# Mount Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyeBlJaz1SXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/Shared\\ drives/CS230/datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9DyMPtm6Aa_",
        "colab_type": "text"
      },
      "source": [
        "# Load required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC2dIxMb4ztt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(0) # Reproducibility"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yatOaC8DJU0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJDN3HomJVwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-XNynFLKwuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va_-fsjrHeKN",
        "colab_type": "text"
      },
      "source": [
        "# Set Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnlgX-xAFhkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prot_lookup = {'A' : 0, 'C' : 1, 'D' : 2, 'E' : 3, \n",
        "               'F' : 4, 'G' : 5, 'H' : 6, 'I' : 7, \n",
        "               'K' : 8, 'L' : 9, 'M' : 10, 'N' : 11, \n",
        "               'P' : 12, 'Q' : 13, 'R' : 14, 'S' : 15, \n",
        "               'T' : 16, 'V' : 17, 'W' : 18, 'Y' : 19}\n",
        "attx_lookup = {'A' : 0, 'T' : 1, 'G' : 2, 'C' : 3}\n",
        "max_prot_len, max_attx_len = 1700, 150\n",
        "prot_dim, attx_dim = 20, 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTpWvSl5Y6aO",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hznyCDuFY_54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_set(line_list):\n",
        "\n",
        "  attx_set_1h = np.zeros((len(line_list), max_attx_len, attx_dim, 1))\n",
        "  attx_set = np.zeros((len(line_list), max_attx_len))\n",
        "  prot_set = np.zeros((len(line_list), max_prot_len))\n",
        "  label_set = np.zeros((len(line_list), 1))\n",
        "  \n",
        "  for i, line in enumerate(line_list):\n",
        "    _, _, attx, prot, label = line.strip().split()\n",
        "    label_set[i, 0] = int(label)\n",
        "    for j in range(len(attx)):\n",
        "      attx_set_1h[i, j, attx_lookup[attx[j]], 0] = 1\n",
        "      attx_set[i, j] = attx_lookup[attx[j]]\n",
        "    for j in range(len(prot)):\n",
        "      prot_set[i, j] = prot_lookup[prot[j]]\n",
        "  \n",
        "  print('Pos Frac: ', sum(label_set) / len(line_list))\n",
        "  return attx_set_1h, attx_set, prot_set, label_set \n",
        "    \n",
        "train_path = 'set2/attx_protein_binding/train_attx_protein_binding.tsv'\n",
        "test_path = 'set2/attx_protein_binding/test_attx_protein_binding.tsv'\n",
        "dev_path = 'set2/attx_protein_binding/dev_attx_protein_binding.tsv'\n",
        "\n",
        "with open(train_path) as f:\n",
        "  train_list = f.readlines()\n",
        "\n",
        "with open(test_path) as f:\n",
        "  test_list = f.readlines()\n",
        "\n",
        "with open(dev_path) as f:\n",
        "  dev_list = f.readlines()\n",
        "\n",
        "print('Generating Train Set')\n",
        "train_attx_1h, train_attx, train_prot, train_label = generate_set(train_list[1:])\n",
        "print(train_attx_1h.shape)\n",
        "print(train_attx.shape)\n",
        "print(train_prot.shape)\n",
        "print(train_label.shape)\n",
        "\n",
        "print('\\nGenerating Test Set')\n",
        "test_attx_1h, test_attx, test_prot, test_label = generate_set(test_list[1:])\n",
        "print(test_attx_1h.shape)\n",
        "print(test_attx.shape)\n",
        "print(test_prot.shape)\n",
        "print(test_label.shape)\n",
        "\n",
        "print('\\nGenerating Dev Set')\n",
        "dev_attx_1h, dev_attx, dev_prot, dev_label = generate_set(dev_list[1:])\n",
        "print(dev_attx_1h.shape)\n",
        "print(dev_attx.shape)\n",
        "print(dev_prot.shape)\n",
        "print(dev_label.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGg9GcFHLpX9",
        "colab_type": "text"
      },
      "source": [
        "# Model Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU0J2ViwLnfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVDJmw9o2TUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(history):\n",
        "\n",
        "  # Plot training & validation accuracy values\n",
        "  plt.plot(history['acc'])\n",
        "  plt.plot(history['val_acc'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Dev'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  plt.plot(history['loss'])\n",
        "  plt.plot(history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Dev'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghY1pKVRLi4z",
        "colab_type": "text"
      },
      "source": [
        "# Hybrid LSTM-CNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmKk3b0WdzjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Protein LSTM Embedding Layer\n",
        "prot_input = Input(shape=(max_prot_len,), dtype='int32')\n",
        "embedding_prot = Embedding(output_dim=20, \n",
        "                           input_dim=prot_dim, \n",
        "                           input_length=max_prot_len)(prot_input)\n",
        "prot_out = LSTM(100)(embedding_prot)\n",
        "\n",
        "# ATTx Convolutional Network\n",
        "attx_input = Input(shape=(max_attx_len, attx_dim, 1), dtype='float32')\n",
        "\n",
        "conv1 = Conv2D(64, \n",
        "               kernel_size=(4, 4), \n",
        "               padding='valid', \n",
        "               strides=1, \n",
        "               activation='relu')(attx_input)\n",
        "\n",
        "pool1 = MaxPooling2D(pool_size=(2, 1), padding='valid')(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, \n",
        "               kernel_size=(5, 1), \n",
        "               padding='valid', \n",
        "               strides=1, \n",
        "               activation='relu')(pool1)\n",
        "\n",
        "pool2 = MaxPooling2D(pool_size=(2, 1), padding='valid')(conv2)\n",
        "\n",
        "conv3 = Conv2D(64, \n",
        "               kernel_size=(5, 1), \n",
        "               padding='valid', \n",
        "               strides=1, \n",
        "               activation='relu')(pool2)\n",
        "\n",
        "drop = Dropout(0.15)(conv3)\n",
        "attx_out = Flatten()(drop)\n",
        "\n",
        "combined = concatenate([attx_out, prot_out])\n",
        "dense1 = Dense(1024, activation='relu', name='Dense1', kernel_regularizer=keras.regularizers.l2(0.002))(combined)\n",
        "dense2 = Dense(1024, activation='relu', name='Dense2', kernel_regularizer=keras.regularizers.l2(0.002))(dense1)\n",
        "pred = Dense(1, activation='sigmoid', name='Dense3', kernel_regularizer=keras.regularizers.l2(0.002))(dense2)\n",
        "\n",
        "model_b = Model(inputs=[prot_input, attx_input], outputs=[pred])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ukfmua2jDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam_b = optimizers.Adam(lr=0.005)\n",
        "model_b.compile(optimizer=adam_b, loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "model_b.summary()\n",
        "plot_model(model_b, show_shapes = True, show_layer_names = False, to_file = 'model_b.png')\n",
        "\n",
        "history_b = model_b.fit([train_prot, train_attx_1h], train_label, epochs=50, batch_size=2048, \n",
        "                    validation_data = ([dev_prot, dev_attx_1h], dev_label))\n",
        "model_b.save('model_b.h5')\n",
        "plot_loss(history_b.history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}