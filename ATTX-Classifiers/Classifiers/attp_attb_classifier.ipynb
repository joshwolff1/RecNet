{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cs230_classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"b5nsm_F4eZex","scrolled":true,"outputId":"f40d21bc-bab8-4ee3-db5b-bc533d838106","executionInfo":{"status":"ok","timestamp":1575627320070,"user_tz":480,"elapsed":2518,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import pandas as pd\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow.keras import regularizers\n","import random\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xYnMMd-qefwi","scrolled":true,"colab":{}},"source":["class_names = [\"attB\", \"attP\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAh4lsiiixcz","colab_type":"code","outputId":"c23d4e3a-1ba7-4741-be88-a87cfb98e3aa","executionInfo":{"status":"ok","timestamp":1575627329081,"user_tz":480,"elapsed":7524,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install xlrd\n","import io\n","from google.colab import auth\n","from googleapiclient.discovery import build\n","from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n","\n","from google.colab import drive \n","\n","auth.authenticate_user()\n","drive_service = build('drive', 'v3')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"njL5LO_iUKmQ","colab_type":"code","colab":{}},"source":["CENTER_PADDING = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NeTfUb6Ni090","colab_type":"code","colab":{}},"source":["### This file retrieval code was adapted from starter code provided by the BioE 101 staff.\n","\n","set_1_train = '12llyDouiydDqzjLo7B6cKHddm5IeoV8f'    # Put helper_function.py id inbetween the quotes\n","set_1_test     = '1XqBhnJlJQPZfYTrSYJI5FP7HT_7-yu30'    # Put p9.xlsx id inbetween the quotes\n","set_1_dev    = '1wHLY52QrrQtDNN3fqNQcWRI855wQg96O'    # Put p10.xlsx id inbetween the quotes\n","set_2_train = '1MixvUK_5XtlbqZlH1nPbm-bTFS99sLwp'    # Put helper_function.py id inbetween the quotes\n","set_2_test     = '18VEZVO5pi4V8IGTWVrIM7O1yOmvkmZfc'    # Put p9.xlsx id inbetween the quotes\n","set_2_dev    = '1pYgUWFhEHsOcAsz3WdYNQ4NstSmxA_Cn'    # Put p10.xlsx id inbetween the quotes\n","\n","\n","file_ids = [set_1_train, set_1_test, set_1_dev, set_2_train, set_2_test, set_2_dev]\n","file_names = [\"set_1_train.tsv\", \"set_1_test.tsv\", \"set_1_dev.tsv\", \"set_2_train.tsv\", \"set_2_test.tsv\", \"set_2_dev.tsv\"]\n","\n","for i in list(range(len(file_ids))):\n","  request = drive_service.files().get_media(fileId=file_ids[i])\n","  downloaded = io.BytesIO()\n","  downloader = MediaIoBaseDownload(downloaded, request)\n","  done = False\n","  while done is False:\n","    _, done = downloader.next_chunk()\n","\n","  downloaded.seek(0)\n","  with open(file_names[i], 'wb') as f:\n","    f.write(downloaded.read())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jjjwAChDipF8","colab_type":"text"},"source":["The code in the following cell for the following functions was adapted from our RNN implementation: load_data(...), pad_zeros(...), get_y(...)."]},{"cell_type":"code","metadata":{"id":"rrhrzs0Ui_yu","colab_type":"code","outputId":"9bc8504c-650c-4f43-bdc2-74addb525c26","executionInfo":{"status":"ok","timestamp":1575628620498,"user_tz":480,"elapsed":7061,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# SET 2\n","\n","char2index = {'A':[1, 0, 0, 0], 'C':[0, 1, 0, 0], 'G':[0, 0, 1, 0], 'T':[0, 0, 0, 1]}\n","\n","def load_data(path):\n","    df = pd.read_csv(path, sep='\\t')\n","\n","    control = list(set([seq for seq in df.loc[df['type'] == \"control\"].att]))\n","    shuf = list(set([seq for seq in df.loc[df['type'] == \"shuf\"].att]))\n","\n","    print(path)\n","\n","    X = [[char2index[char] for char in seq] for seq in df.loc[df['type'] == \"attb\"].att]\n","    Y = [[char2index[char] for char in seq] for seq in df.loc[df['type'] == \"attp\"].att]\n","    \n","    Z = [[char2index[char] for char in seq] for seq in control]\n","    Z += [[char2index[char] for char in seq] for seq in shuf]\n","    return X, Y, Z\n","\n","train_attb, train_attp, train_control = load_data('set_2_train.tsv')\n","dev_attb, dev_attp, dev_control = load_data('set_2_dev.tsv')\n","test_attb, test_attp, test_control = load_data('set_2_test.tsv')\n","\n","\n","def pad_zeros(data, max_pad=160, centered_pad=True):\n","    padded_data = []\n","    for row in data:\n","        if max_pad - len(row) > 0:\n","            if centered_pad:\n","                diff = max_pad - len(row)\n","                left_val = int(diff / 2)\n","                right_val = int(diff / 2) + int(diff % 2)\n","                row = [[0, 0, 0, 0]]*left_val + row + [[0, 0, 0, 0]]*right_val\n","            else:\n","                row = row + [[0, 0, 0, 0]]*(max_pad - len(row))\n","        padded_data.append(row)\n","    return np.array(padded_data)\n","\n","\n","def get_y(attb, attp):\n","    y_to_return = np.array(len(attb) * [0] + len(attp) * [1])\n","    return y_to_return.reshape(y_to_return.shape[0], 1)\n","\n","print(len(train_attb))\n","print(len(train_attp))\n","print(len(train_attb + train_attp))\n","train_x = train_attb + train_attp\n","dev_x = dev_attb + dev_attp\n","test_x = test_attb + test_attp\n","\n","train_x, train_y = pad_zeros(train_x, centered_pad=CENTER_PADDING), get_y(train_attb, train_attp)\n","dev_x, dev_y = pad_zeros(dev_x, centered_pad=CENTER_PADDING), get_y(dev_attb, dev_attp)\n","test_x, test_y = pad_zeros(test_x, centered_pad=CENTER_PADDING), get_y(test_attb, test_attp)\n","\n","print(train_x[0])\n","print(train_y.shape)\n","print(train_x.shape)\n","print(train_x.shape)\n","print(dev_x.shape)\n","print(test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["set_2_train.tsv\n","set_2_dev.tsv\n","set_2_test.tsv\n","9613\n","10554\n","20167\n","[[0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(20167, 1)\n","(20167, 160, 4)\n","(20167, 160, 4)\n","(3305, 160, 4)\n","(6554, 160, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575625826480,"user_tz":480,"elapsed":19288,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"id":"8K70f7dUlwgD","outputId":"70f54fa6-832b-481f-95a3-667bb087a169","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# SET 1\n","\n","char2index = {'A':[1, 0, 0, 0], 'C':[0, 1, 0, 0], 'G':[0, 0, 1, 0], 'T':[0, 0, 0, 1]}\n","\n","def load_data(path):\n","    df = pd.read_csv(path, sep='\\t')\n","\n","    attb = list(set([seq for seq in df.attb]))\n","    attp = list(set([seq for seq in df.attp]))\n","\n","    X = [[char2index[char] for char in seq] for seq in attb]\n","    Y = [[char2index[char] for char in seq] for seq in attp]\n","    return X, Y\n","\n","train_attb, train_attp = load_data('set_1_train.tsv')\n","dev_attb, dev_attp = load_data('set_1_dev.tsv')\n","test_attb, test_attp = load_data('set_1_test.tsv')\n","\n","def pad_zeros(data, max_pad=160, centered_pad=False):\n","    padded_data = []\n","    for row in data:\n","        if max_pad - len(row) > 0:\n","            if centered_pad:\n","                diff = max_pad - len(row)\n","                left_val = int(diff / 2)\n","                right_val = int(diff / 2) + int(diff % 2)\n","                row = [[0, 0, 0, 0]]*left_val + row + [[0, 0, 0, 0]]*right_val\n","            else:\n","                row = row + [[0, 0, 0, 0]]*(max_pad - len(row))\n","        padded_data.append(row)\n","    return np.array(padded_data)\n","\n","\n","def get_y(attb, attp):\n","    y_to_return = np.array(len(attb) * [0] + len(attp) * [1])\n","    return y_to_return.reshape(y_to_return.shape[0], 1)\n","\n","print(len(train_attb))\n","print(len(train_attp))\n","print(len(train_attb + train_attp))\n","train_x = train_attb + train_attp\n","dev_x = dev_attb + dev_attp\n","test_x = test_attb + test_attp\n","\n","\n","train_x, train_y = pad_zeros(train_x, centered_pad=CENTER_PADDING), get_y(train_attb, train_attp)\n","dev_x, dev_y = pad_zeros(dev_x, centered_pad=CENTER_PADDING), get_y(dev_attb, dev_attp)\n","test_x, test_y = pad_zeros(test_x, centered_pad=CENTER_PADDING), get_y(test_attb, test_attp)\n","\n","print(train_x[0])\n","print(train_y.shape)\n","print(train_x.shape)\n","print(train_x.shape)\n","print(test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["17406\n","18833\n","36239\n","[[0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(36239, 1)\n","(36239, 160, 4)\n","(36239, 160, 4)\n","(10870, 160, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I9N6-SIiipGH","colab_type":"text"},"source":["The code for this model was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JKIpFEKOe2Nr","scrolled":true,"colab":{}},"source":["def get_model(l1_val=None, middle_layer_val=128, middle_layer_activation=\"relu\"):\n","    # Our RNN\n","    model_to_return = keras.Sequential([\n","        keras.layers.Flatten(input_shape=(160, 4))\n","    ])\n","    if l1_val is not None:\n","        model_to_return.add(keras.layers.Dense(middle_layer_val, input_dim=160,\n","                                               activation=middle_layer_activation,\n","                                               activity_regularizer=regularizers.l1(l1_val)))\n","    else:\n","        model_to_return.add(keras.layers.Dense(middle_layer_val, activation=middle_layer_activation))\n","\n","    model_to_return.add(keras.layers.Dense(2, activation='softmax'))\n","    return model_to_return\n","\n","def fit_model(model, train_x_arr, train_y_arr, verbose=2, epochs=25):\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    model.fit(train_x_arr, train_y_arr, epochs=epochs, shuffle=True, verbose=verbose)\n","\n","def eval_model(model, test_x_arr, test_y_arr):\n","    return model.evaluate(test_x_arr,  test_y_arr, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m8FoHZ9MfEry","scrolled":false,"colab":{}},"source":["model = get_model()\n","fit_model(model, train_x, train_y, epochs=5)\n","print(train_x[0])\n","dev_loss, dev_acc = eval_model(model, dev_x, dev_y)\n","print('Development  set accuracy:', dev_acc)\n","test_loss, test_acc = eval_model(model, test_x, test_y)\n","print('Test  set accuracy:', test_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K45VoIYifHLB","scrolled":true,"colab":{}},"source":["predictions = model.predict(test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIVSXX4CipGe","colab_type":"text"},"source":["The code for plotting the image of our one-hot encoded sequence was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5SsYi7tIfHgV","scrolled":true,"colab":{}},"source":["def plot_image(i, predictions_array, true_label, img):\n","    \"\"\"\n","    Plots a sample image from our dataset.\n","    \"\"\"\n","    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    plt.imshow(img, cmap=plt.cm.binary)\n","\n","    predicted_label = np.argmax(predictions_array)\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","    print(true_label)\n","    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label[0]]),\n","                                color=color)\n","\n","i = 0\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(i, predictions[i], test_y, test_x)\n","plt.show()\n","print(predictions.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PYPxhP3ifO3U","scrolled":true,"colab":{}},"source":["plt.figure()\n","plt.imshow(train_x[0])\n","plt.grid(False)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xespynnyipGv","colab_type":"text"},"source":["The code for plotting the image of our one-hot encoded sequence was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"]},{"cell_type":"code","metadata":{"id":"MXuQWTm0ipGw","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(45,45))\n","range_to_show = 20\n","for i in range(range_to_show):\n","    plt.subplot(4, 5, i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    item_to_get = len(train_x) - i if int(i / 5) % 2 == 1 else i\n","    plt.imshow(train_x[item_to_get])\n","    plt.xlabel(class_names[train_y[item_to_get][0]])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10OZrDrtipG9","colab_type":"text"},"source":["## Regularization and Data Augmentation\n","\n","We now have a training accuracy of 99.3% and a test accuracy of 85.6%. We see that we have high variance and perhaps are overfitting our training set."]},{"cell_type":"code","metadata":{"id":"QiOxGDSIipHB","colab_type":"code","colab":{}},"source":["def get_hyperparameters(simple=False):\n","    \"\"\"\n","    :param simple: Whether or not to return only two hyperparameter configurations. For debugging.\n","    :return: Several hyperparamter configurations consisting of varying combinations of activation functions, hidden unit amounts, and l1 regularization constants.\n","    \"\"\"\n","    activations = [\"relu\", \"sigmoid\"]\n","    layer_vals = [8, 32, 64, 128]\n","    l1_vals = np.random.exponential(scale=0.015, size=(5,)).reshape(5, 1)\n","    hyperparameters_to_return = []\n","    print(l1_vals)\n","    if simple:\n","        return [{\n","                    'activation': activations[0], \n","                    'layer_val': 128,\n","                    'l1': 0.05\n","                },\n","                {\n","                    'activation': activations[1], \n","                    'layer_val': 128,\n","                    'l1': 0.05\n","                }]\n","\n","    for act in activations:\n","        for layer_val in layer_vals:\n","            for l_val in l1_vals:\n","                hyperparameters_to_return.append({\n","                    'activation': act, \n","                    'layer_val': layer_val,\n","                    'l1': l_val\n","                })\n","    return hyperparameters_to_return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-c0u2PRipHF","colab_type":"code","colab":{}},"source":["dev_accuracies = []\n","hyperparameters = get_hyperparameters(simple=False)\n","print(hyperparameters)\n","print(\"We are testing \" + str(len(hyperparameters)) + \".\")\n","for param in hyperparameters:\n","    print(param)\n","for hyper_params in hyperparameters:\n","    model_extended = get_model(l1_val=hyper_params['l1'],\n","                               middle_layer_val=hyper_params['layer_val'], \n","                               middle_layer_activation=hyper_params['activation'])\n","    fit_model(model_extended, \n","              train_x, \n","              train_y,\n","              verbose=0)\n","    dev_loss, dev_acc = eval_model(model_extended, dev_x, dev_y)\n","    dev_accuracies.append(dev_acc)\n","    print(dev_accuracies)\n","    print(hyper_params)\n","    print('Development set accuracy:', dev_acc)\n","\n","dev_accuracies = np.array(dev_accuracies)\n","print(dev_accuracies)\n","print(max(dev_accuracies))\n","index_of_hyper_to_get = dev_accuracies.argmax(axis=0)\n","print(hyperparameters[index_of_hyper_to_get])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yBUEJZWUipHM","colab_type":"text"},"source":["None of these configurations resulted in an improved development set accuracy."]},{"cell_type":"markdown","metadata":{"id":"D7DX3ejOipHN","colab_type":"text"},"source":["## CNN"]},{"cell_type":"markdown","metadata":{"id":"9s2KoW8dipHQ","colab_type":"text"},"source":["The code for the CNN was adapted from the following source: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"]},{"cell_type":"code","metadata":{"id":"wcyNRlTuipHR","colab_type":"code","colab":{}},"source":["def create_model(input_shape, kernel_size=3):    \n","    model_to_return = Sequential()\n","    convo_add = Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu', input_shape=(input_shape[1], input_shape[2], 1))\n","    model_to_return.add(convo_add)\n","    model_to_return.add(Conv2D(32, kernel_size=kernel_size, padding='same',activation='relu'))\n","    model_to_return.add(MaxPooling2D(pool_size=(2, 2)))\n","    \n","    model_to_return.add(Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'))\n","    model_to_return.add(Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'))\n","    model_to_return.add(MaxPooling2D(pool_size=(2, 2)))\n","    model_to_return.add(Dropout(0.25))\n","    \n","    model_to_return.add(Flatten())\n","    model_to_return.add(Dense(512, activation='relu'))\n","    model_to_return.add(Dropout(0.5))\n","    model_to_return.add(Dense(2, activation='softmax'))\n","    return model_to_return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qEs-UCZipHb","colab_type":"code","outputId":"28e2a995-47d4-4e01-ac03-20570a1ad14f","colab":{}},"source":["train_x_cnn, train_y_cnn = np.array(train_x), np.array(train_y)\n","print(train_x_cnn.shape)\n","print(train_y_cnn.shape)\n","train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","model = create_model(train_x_cnn.shape)\n","fit_model(model, train_x_cnn, train_y_cnn)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(40602, 160, 4)\n","(40602, 1)\n","Epoch 1/25\n","165s - loss: 0.5509 - acc: 0.7150\n","Epoch 2/25\n","171s - loss: 0.4486 - acc: 0.7877\n","Epoch 3/25\n","170s - loss: 0.3851 - acc: 0.8212\n","Epoch 4/25\n","187s - loss: 0.3340 - acc: 0.8479\n","Epoch 5/25\n","195s - loss: 0.2923 - acc: 0.8701\n","Epoch 6/25\n","202s - loss: 0.2594 - acc: 0.8868\n","Epoch 7/25\n","212s - loss: 0.2287 - acc: 0.9006\n","Epoch 8/25\n","218s - loss: 0.2061 - acc: 0.9112\n","Epoch 9/25\n","214s - loss: 0.1895 - acc: 0.9181\n","Epoch 10/25\n","236s - loss: 0.1694 - acc: 0.9297\n","Epoch 11/25\n","223s - loss: 0.1560 - acc: 0.9352\n","Epoch 12/25\n","209s - loss: 0.1441 - acc: 0.9420\n","Epoch 13/25\n","207s - loss: 0.1391 - acc: 0.9432\n","Epoch 14/25\n","208s - loss: 0.1270 - acc: 0.9493\n","Epoch 15/25\n","247s - loss: 0.1218 - acc: 0.9521\n","Epoch 16/25\n","290s - loss: 0.1153 - acc: 0.9544\n","Epoch 17/25\n","233s - loss: 0.1126 - acc: 0.9557\n","Epoch 18/25\n","216s - loss: 0.1057 - acc: 0.9588\n","Epoch 19/25\n","211s - loss: 0.1015 - acc: 0.9608\n","Epoch 20/25\n","226s - loss: 0.1001 - acc: 0.9612\n","Epoch 21/25\n","199s - loss: 0.0973 - acc: 0.9631\n","Epoch 22/25\n","229s - loss: 0.0901 - acc: 0.9650\n","Epoch 23/25\n","246s - loss: 0.0942 - acc: 0.9640\n","Epoch 24/25\n","250s - loss: 0.0862 - acc: 0.9670\n","Epoch 25/25\n","223s - loss: 0.0858 - acc: 0.9682\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r-_DTgRHipHh","colab_type":"code","outputId":"fc5599b4-fddc-4952-ea20-548d4cd3c1b0","colab":{}},"source":["dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n","print('Development set accuracy:', dev_acc)\n","\n","test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","test_loss, test_acc = eval_model(model, test_x_cnn, test_y)\n","print('Test set accuracy:', test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Development set accuracy: 0.8749575839634867\n","Test set accuracy: 0.8793405822309349\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z708OYjRipHq","colab_type":"text"},"source":["The visualization for the classes was adapted from the following source: https://jacobgil.github.io/deeplearning/class-activation-maps"]},{"cell_type":"code","metadata":{"id":"jq0NE15zipHq","colab_type":"code","colab":{}},"source":["def visualize_class_activation_map():\n","    original_img = dev_x_cnn[0]\n","    width, height, _ = original_img.shape # original_img.shape\n","    \n","    img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n","    \n","    class_weights = model.layers[-1].get_weights()[0]\n","    \n","    get_output = K.function([model.layers[0].input], \\\n","                [model.layers[len(model.layers) - 1].output, \n","    model.layers[-1].output])\n","    [conv_outputs, predictions] = get_output([img])\n","    conv_outputs = conv_outputs[0, :, :, :]\n","\n","    # Class activation map.\n","    cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n","    target_class = 1\n","    for i, w in enumerate(class_weights[:, target_class]):\n","            cam += w * conv_outputs[i, :, :]\n","\n","model.summary()\n","\n","layer_outputs = [layer.output for layer in model.layers[:12]]\n","\n","from keras import models\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","\n","img_tensor = np.expand_dims(dev_x_cnn[10], axis=0)\n","img_tensor = img_tensor / 255\n","img_tensor_to_show = img_tensor[0,:,:,0:1].reshape(160,4)\n","print(img_tensor_to_show.shape)\n","plt.imshow(img_tensor_to_show)\n","plt.show()\n","\n","activations = activation_model.predict(img_tensor) \n","first_layer_activation = activations[0]\n","print(first_layer_activation.shape)\n","plt.matshow(first_layer_activation[0, :, :, 32], cmap='viridis')\n","\n","DEBUG = False\n","\n","if DEBUG:\n","    last_layer_act = activations[3]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[:, :], cmap='viridis')\n","    \n","    last_layer_act = activations[1]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[0, :, :, 1], cmap='viridis')\n","\n","    last_layer_act = activations[len(activations) - 2]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[:], cmap='viridis')\n","\n","\n","    last_layer_act = activations[len(activations) - 1]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[:], cmap='viridis')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kgMISayipHu","colab_type":"code","colab":{}},"source":["model = create_model(train_x_cnn.shape)\n","fit_model(model, train_x_cnn, train_y_cnn, epochs=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCDZyco8ipHy","colab_type":"code","colab":{}},"source":["dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n","print('Development set accuracy:', dev_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKOgoy-EUGQV","colab_type":"code","outputId":"5ec995aa-cc09-40ee-dc30-f48785ae9791","executionInfo":{"status":"ok","timestamp":1575628240156,"user_tz":480,"elapsed":319451,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# This represents our second (and much more successful) run of hyperparameter testing\n","\n","def hyperparameter_testing():\n","  print(\"set 2\")\n","  print(\"right padding\")\n","  cnn_epochs = [15]\n","  nn_epochs = [5]\n","  tests = [\n","           [\"cnn\", 3],\n","           [\"cnn\", 4],\n","           [\"nn\", None],\n","          ]\n","  print(train_x[0])\n","  results = []\n","  for test in tests:\n","    if test[0] == \"nn\":\n","      result = []\n","      for epoch in nn_epochs:\n","        model = get_model()\n","        fit_model(model, train_x, train_y, epochs=epoch)\n","        train_loss, train_acc = eval_model(model, train_x, train_y)\n","        dev_loss, dev_acc = eval_model(model, dev_x, dev_y)\n","        print('Development  set accuracy:', dev_acc)\n","        test_loss, test_acc = eval_model(model, test_x, test_y)\n","        print('Test  set accuracy:', test_acc)\n","        result.append([train_acc, dev_acc, test_acc])\n","      results.append(result)\n","    else:\n","      result = []\n","      \n","\n","      for epoch in cnn_epochs:\n","        \n","        train_x_cnn, train_y_cnn = np.array(train_x).astype(int), np.array(train_y).astype(int)\n","\n","        kernel_size = test[1]\n","        model = create_model(train_x_cnn.shape, kernel_size=kernel_size)\n","\n","        print(train_x[0])\n","        print(train_x_cnn.shape)\n","        print(train_y_cnn.shape)\n","        train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","\n","        fit_model(model, train_x_cnn, train_y_cnn, epochs=epoch)\n","\n","        train_loss, train_acc = eval_model(model, train_x_cnn, train_y_cnn)\n","\n","        dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","\n","        dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n","        print('Development set accuracy:', dev_acc)\n","\n","        test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","\n","        test_loss, test_acc = eval_model(model, test_x_cnn, test_y)\n","        print('Test set accuracy:', test_acc)\n","        result.append([train_acc, dev_acc, test_acc])\n","      results.append(result)\n","  return results\n","\n","results = hyperparameter_testing()\n","print(results)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["set 2\n","right padding\n","[[0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","[[0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(20167, 160, 4)\n","(20167, 1)\n","Epoch 1/15\n"," - 12s - loss: 0.4549 - acc: 0.7866\n","Epoch 2/15\n"," - 11s - loss: 0.3519 - acc: 0.8468\n","Epoch 3/15\n"," - 10s - loss: 0.2913 - acc: 0.8793\n","Epoch 4/15\n"," - 10s - loss: 0.2466 - acc: 0.8982\n","Epoch 5/15\n"," - 9s - loss: 0.2034 - acc: 0.9164\n","Epoch 6/15\n"," - 8s - loss: 0.1674 - acc: 0.9333\n","Epoch 7/15\n"," - 8s - loss: 0.1362 - acc: 0.9482\n","Epoch 8/15\n"," - 9s - loss: 0.1145 - acc: 0.9556\n","Epoch 9/15\n"," - 9s - loss: 0.1016 - acc: 0.9601\n","Epoch 10/15\n"," - 8s - loss: 0.0838 - acc: 0.9686\n","Epoch 11/15\n"," - 8s - loss: 0.0747 - acc: 0.9728\n","Epoch 12/15\n"," - 9s - loss: 0.0685 - acc: 0.9747\n","Epoch 13/15\n"," - 9s - loss: 0.0576 - acc: 0.9803\n","Epoch 14/15\n"," - 8s - loss: 0.0594 - acc: 0.9774\n","Epoch 15/15\n"," - 9s - loss: 0.0542 - acc: 0.9789\n","Development set accuracy: 0.9361573373676249\n","Test set accuracy: 0.9263045468598122\n","[[0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(20167, 160, 4)\n","(20167, 1)\n","Epoch 1/15\n"," - 11s - loss: 0.4563 - acc: 0.7855\n","Epoch 2/15\n"," - 10s - loss: 0.3436 - acc: 0.8552\n","Epoch 3/15\n"," - 11s - loss: 0.2694 - acc: 0.8902\n","Epoch 4/15\n"," - 11s - loss: 0.2169 - acc: 0.9136\n","Epoch 5/15\n"," - 11s - loss: 0.1696 - acc: 0.9337\n","Epoch 6/15\n"," - 11s - loss: 0.1313 - acc: 0.9487\n","Epoch 7/15\n"," - 11s - loss: 0.1057 - acc: 0.9583\n","Epoch 8/15\n"," - 11s - loss: 0.0891 - acc: 0.9672\n","Epoch 9/15\n"," - 10s - loss: 0.0756 - acc: 0.9714\n","Epoch 10/15\n"," - 11s - loss: 0.0631 - acc: 0.9759\n","Epoch 11/15\n"," - 11s - loss: 0.0596 - acc: 0.9768\n","Epoch 12/15\n"," - 11s - loss: 0.0533 - acc: 0.9804\n","Epoch 13/15\n"," - 11s - loss: 0.0475 - acc: 0.9830\n","Epoch 14/15\n"," - 11s - loss: 0.0425 - acc: 0.9836\n","Epoch 15/15\n"," - 11s - loss: 0.0451 - acc: 0.9834\n","Development set accuracy: 0.9355521936640256\n","Test set accuracy: 0.9273725969055858\n","Train on 20167 samples\n","Epoch 1/5\n","20167/20167 - 2s - loss: 0.4615 - acc: 0.7843\n","Epoch 2/5\n","20167/20167 - 2s - loss: 0.3109 - acc: 0.8741\n","Epoch 3/5\n","20167/20167 - 2s - loss: 0.1874 - acc: 0.9332\n","Epoch 4/5\n","20167/20167 - 2s - loss: 0.1025 - acc: 0.9710\n","Epoch 5/5\n","20167/20167 - 2s - loss: 0.0504 - acc: 0.9905\n","Development  set accuracy: 0.91649014\n","Test  set accuracy: 0.9101312\n","[[[0.9976198740516685, 0.9361573373676249, 0.9263045468598122]], [[0.9951405761888233, 0.9355521936640256, 0.9273725969055858]], [[0.9983141, 0.91649014, 0.9101312]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9HQrU9dMVc8i","colab_type":"code","outputId":"9e1127f5-6c6c-4238-d789-41e7268da620","executionInfo":{"status":"ok","timestamp":1575628785839,"user_tz":480,"elapsed":143106,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_x_cnn, train_y_cnn = np.array(train_x).astype(int), np.array(train_y).astype(int)\n","\n","best_model = create_model(train_x_cnn.shape, kernel_size=3)\n","\n","print(train_x[0])\n","print(train_x_cnn.shape)\n","print(train_y_cnn.shape)\n","train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","\n","fit_model(best_model, train_x_cnn, train_y_cnn, epochs=15)\n","\n","train_loss, train_acc = eval_model(best_model, train_x_cnn, train_y_cnn)\n","\n","dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","\n","dev_loss, dev_acc = eval_model(best_model, dev_x_cnn, dev_y)\n","print('Development set accuracy:', dev_acc)\n","\n","test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","\n","test_loss, test_acc = eval_model(best_model, test_x_cnn, test_y)\n","print('Test set accuracy:', test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(20167, 160, 4)\n","(20167, 1)\n","Epoch 1/15\n"," - 11s - loss: 0.4729 - acc: 0.7701\n","Epoch 2/15\n"," - 10s - loss: 0.3688 - acc: 0.8384\n","Epoch 3/15\n"," - 9s - loss: 0.3078 - acc: 0.8711\n","Epoch 4/15\n"," - 9s - loss: 0.2590 - acc: 0.8943\n","Epoch 5/15\n"," - 9s - loss: 0.2162 - acc: 0.9127\n","Epoch 6/15\n"," - 9s - loss: 0.1780 - acc: 0.9287\n","Epoch 7/15\n"," - 9s - loss: 0.1488 - acc: 0.9415\n","Epoch 8/15\n"," - 9s - loss: 0.1257 - acc: 0.9527\n","Epoch 9/15\n"," - 9s - loss: 0.1090 - acc: 0.9586\n","Epoch 10/15\n"," - 9s - loss: 0.0963 - acc: 0.9625\n","Epoch 11/15\n"," - 9s - loss: 0.0788 - acc: 0.9702\n","Epoch 12/15\n"," - 8s - loss: 0.0730 - acc: 0.9723\n","Epoch 13/15\n"," - 8s - loss: 0.0731 - acc: 0.9722\n","Epoch 14/15\n"," - 8s - loss: 0.0605 - acc: 0.9767\n","Epoch 15/15\n"," - 9s - loss: 0.0613 - acc: 0.9770\n","Development set accuracy: 0.9364599092464765\n","Test set accuracy: 0.9313396398054233\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"enWE2QDJyMF9","colab_type":"code","outputId":"ac898ef0-ecd2-4c94-d15c-e9168ff00f84","executionInfo":{"status":"ok","timestamp":1575628785844,"user_tz":480,"elapsed":140893,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"source":["best_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_25 (Conv2D)           (None, 160, 4, 64)        640       \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 160, 4, 32)        18464     \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 80, 2, 32)         0         \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 80, 2, 64)         18496     \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 80, 2, 64)         36928     \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 40, 1, 64)         0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 40, 1, 64)         0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 2560)              0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 512)               1311232   \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 2)                 1026      \n","=================================================================\n","Total params: 1,386,786\n","Trainable params: 1,386,786\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EfP2SGmwySGO","colab_type":"code","colab":{}},"source":["best_model.save(\"double.h5\")\n","from google.colab import files\n","files.download('double.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwyrWfVx11ug","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}