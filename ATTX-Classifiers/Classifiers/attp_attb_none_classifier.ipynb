{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cs230_classifier_triple.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575612130978,"user_tz":480,"elapsed":1848,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"id":"b5nsm_F4eZex","outputId":"c4fc09b6-b651-4844-cd55-604ccac1c4b1","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":81}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import pandas as pd\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow.keras import regularizers\n","import random\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Sveae-c1H44E","colab_type":"code","outputId":"611209a5-1a00-4f86-a8d8-9325b585b93a","executionInfo":{"status":"ok","timestamp":1575612139412,"user_tz":480,"elapsed":9453,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install xlrd\n","import io\n","from google.colab import auth\n","from googleapiclient.discovery import build\n","from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n","\n","from google.colab import drive \n","\n","auth.authenticate_user()\n","drive_service = build('drive', 'v3')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o3mAW4ROLBCi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgQxNdy2JQ2T","colab_type":"code","colab":{}},"source":["### This file retrieval code was adapted from starter code provided by the BioE 101 staff.\n","\n","set_1_train = '12llyDouiydDqzjLo7B6cKHddm5IeoV8f'    # Put helper_function.py id inbetween the quotes\n","set_1_test     = '1XqBhnJlJQPZfYTrSYJI5FP7HT_7-yu30'    # Put p9.xlsx id inbetween the quotes\n","set_1_dev    = '1wHLY52QrrQtDNN3fqNQcWRI855wQg96O'    # Put p10.xlsx id inbetween the quotes\n","set_2_train = '1MixvUK_5XtlbqZlH1nPbm-bTFS99sLwp'    # Put helper_function.py id inbetween the quotes\n","set_2_test     = '18VEZVO5pi4V8IGTWVrIM7O1yOmvkmZfc'    # Put p9.xlsx id inbetween the quotes\n","set_2_dev    = '1pYgUWFhEHsOcAsz3WdYNQ4NstSmxA_Cn'    # Put p10.xlsx id inbetween the quotes\n","\n","\n","file_ids = [set_1_train, set_1_test, set_1_dev, set_2_train, set_2_test, set_2_dev]\n","file_names = [\"set_1_train.tsv\", \"set_1_test.tsv\", \"set_1_dev.tsv\", \"set_2_train.tsv\", \"set_2_test.tsv\", \"set_2_dev.tsv\"]\n","\n","for i in list(range(len(file_ids))):\n","  request = drive_service.files().get_media(fileId=file_ids[i])\n","  downloaded = io.BytesIO()\n","  downloader = MediaIoBaseDownload(downloaded, request)\n","  done = False\n","  while done is False:\n","    _, done = downloader.next_chunk()\n","\n","  downloaded.seek(0)\n","  with open(file_names[i], 'wb') as f:\n","    f.write(downloaded.read())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xYnMMd-qefwi","scrolled":true,"colab":{}},"source":["class_names = [\"attB\", \"attP\", \"control\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvCymQE6AZWt","colab_type":"code","colab":{}},"source":["CENTER_PADDING = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uk-_flSqHiYd","colab_type":"text"},"source":["The code in the following cell for the following functions was adapted from our RNN implementation: load_data(...), pad_zeros(...), get_y(...)."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1575628705271,"user_tz":480,"elapsed":10561,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"id":"8K70f7dUlwgD","outputId":"bd1072c1-351a-4298-b49c-d62cf7e4587d","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":191}},"source":["# SET 2\n","\n","char2index = {'A':[1, 0, 0, 0], 'C':[0, 1, 0, 0], 'G':[0, 0, 1, 0], 'T':[0, 0, 0, 1]}\n","\n","def load_data(path):\n","    df = pd.read_csv(path, sep='\\t')\n","\n","    # No duplicates in set 2, but just in case\n","    attb = list(set([seq for seq in df.loc[df['type'] == \"attb\"].att]))\n","    attp = list(set([seq for seq in df.loc[df['type'] == \"attp\"].att]))\n","    control = list(set([seq for seq in df.loc[df['type'] == \"control\"].att]))\n","    shuf = list(set([seq for seq in df.loc[df['type'] == \"shuf\"].att]))\n","\n","    print(path)\n","\n","    X = [[char2index[char] for char in seq] for seq in attb]\n","    Y = [[char2index[char] for char in seq] for seq in attp]\n","    \n","    Z = [[char2index[char] for char in seq] for seq in control]\n","    Z += [[char2index[char] for char in seq] for seq in shuf]\n","    return X, Y, Z\n","\n","# train_attb, train_attp, train_control = load_data('set2/attx_protein_binding/train.tsv')\n","# dev_attb, dev_attp, dev_control = load_data('set2/attx_protein_binding/dev.tsv')\n","# test_attb, test_attp, test_control = load_data('set2/attx_protein_binding/test.tsv')\n","train_attb, train_attp, train_control = load_data('set_2_train.tsv')\n","dev_attb, dev_attp, dev_control = load_data('set_2_dev.tsv')\n","test_attb, test_attp, test_control = load_data('set_2_test.tsv')\n","\n","\n","def pad_zeros(data, max_pad=160, centered_pad=True):\n","    padded_data = []\n","    for row in data:\n","        if max_pad - len(row) > 0:\n","            if centered_pad:\n","                diff = max_pad - len(row)\n","                left_val = int(diff / 2)\n","                right_val = int(diff / 2) + int(diff % 2)\n","                row = [[0, 0, 0, 0]]*left_val + row + [[0, 0, 0, 0]]*right_val\n","            else:\n","                row = row + [[0, 0, 0, 0]]*(max_pad - len(row))\n","        padded_data.append(row)\n","    return np.array(padded_data)\n","\n","\n","def get_y(attb, attp, control):\n","    y_to_return = np.array(len(attb) * [0] + len(attp) * [1] + len(control) * [2])\n","    return y_to_return.reshape(y_to_return.shape[0], 1)\n","\n","print(len(train_attb))\n","print(len(train_attp))\n","print(len(train_attb + train_attp))\n","train_x = train_attb + train_attp + train_control\n","dev_x = dev_attb + dev_attp + dev_control\n","test_x = test_attb + test_attp + test_control\n","\n","train_x, train_y = pad_zeros(train_x, centered_pad=CENTER_PADDING), get_y(train_attb, train_attp, train_control)\n","dev_x, dev_y = pad_zeros(dev_x, centered_pad=CENTER_PADDING), get_y(dev_attb, dev_attp, dev_control)\n","test_x, test_y = pad_zeros(test_x, centered_pad=CENTER_PADDING), get_y(test_attb, test_attp, test_control)\n","\n","print(train_y.shape)\n","print(train_x.shape)\n","print(train_x.shape)\n","print(test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["set_2_train.tsv\n","set_2_dev.tsv\n","set_2_test.tsv\n","9613\n","10554\n","20167\n","(60501, 1)\n","(60501, 160, 4)\n","(60501, 160, 4)\n","(19662, 160, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YHvWFwbMMSoT","colab_type":"code","outputId":"1b5205ce-5d0b-4679-c25e-578dee863d3e","executionInfo":{"status":"ok","timestamp":1575626290854,"user_tz":480,"elapsed":12841,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#### SET 1 IS FORMATTED DIFF FROM SET 2\n","#### JUST USE OLD CODE FROM CS_230_CLASSIFIER.IPYNB (ORIGINAL)\n","\n","char2index = {'A':[1, 0, 0, 0], 'C':[0, 1, 0, 0], 'G':[0, 0, 1, 0], 'T':[0, 0, 0, 1]}\n","\n","def load_data(path):\n","    df = pd.read_csv(path, sep='\\t')\n","    print(path)\n","\n","    # Remove duplicates\n","    attb = list(set([seq for seq in df.attb]))\n","    attp = list(set([seq for seq in df.attp]))\n","\n","    B = [[char2index[char] for char in seq] for seq in attb]\n","    P = [[char2index[char] for char in seq] for seq in attp]\n","    return B, P\n","\n","train_attb, train_attp = load_data('set_1_train.tsv')\n","dev_attb, dev_attp = load_data('set_1_dev.tsv')\n","test_attb, test_attp = load_data('set_1_test.tsv')\n","\n","def pad_zeros(data, max_pad=160, centered_pad=False):\n","    padded_data = []\n","    for row in data:\n","        if max_pad - len(row) > 0:\n","            if centered_pad:\n","                diff = max_pad - len(row)\n","                left_val = int(diff / 2)\n","                right_val = int(diff / 2) + int(diff % 2)\n","                row = [[0, 0, 0, 0]]*left_val + row + [[0, 0, 0, 0]]*right_val\n","            else:\n","                row = row + [[0, 0, 0, 0]]*(max_pad - len(row))\n","        padded_data.append(row)\n","    return np.array(padded_data)\n","\n","print(len(train_attb))\n","print(len(train_attp))\n","print(len(train_attb + train_attp))\n","train_x = train_attb + train_attp + train_control\n","dev_x = dev_attb + dev_attp + dev_control\n","test_x = test_attb + test_attp + test_control\n","\n","train_x, train_y = pad_zeros(train_x, centered_pad=CENTER_PADDING), get_y(train_attb, train_attp, train_control)\n","dev_x, dev_y = pad_zeros(dev_x, centered_pad=CENTER_PADDING), get_y(dev_attb, dev_attp, dev_control)\n","test_x, test_y = pad_zeros(test_x, centered_pad=CENTER_PADDING), get_y(test_attb, test_attp, test_control)\n","\n","print(train_x[0])\n","print(train_y.shape)\n","print(train_x.shape)\n","print(train_x.shape)\n","print(test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["set_1_train.tsv\n","set_1_dev.tsv\n","set_1_test.tsv\n","17406\n","18833\n","36239\n","[[0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(76573, 1)\n","(76573, 160, 4)\n","(76573, 160, 4)\n","(23978, 160, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c9APcEpxHiYq","colab_type":"text"},"source":["The code for this model was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JKIpFEKOe2Nr","scrolled":true,"colab":{}},"source":["def get_model(l1_val=None, middle_layer_val=128, middle_layer_activation=\"relu\"):\n","    model_to_return = keras.Sequential([\n","        keras.layers.Flatten(input_shape=(160, 4))\n","    ])\n","    if l1_val is not None:\n","        model_to_return.add(keras.layers.Dense(middle_layer_val, input_dim=160,\n","                                               activation=middle_layer_activation,\n","                                               activity_regularizer=regularizers.l1(l1_val)))\n","    else:\n","        model_to_return.add(keras.layers.Dense(middle_layer_val, activation=middle_layer_activation))\n","\n","    model_to_return.add(keras.layers.Dense(3, activation='softmax'))\n","    return model_to_return\n","\n","def fit_model(model, train_x_arr, train_y_arr, verbose=2, epochs=25):\n","    model.compile(optimizer='adam',\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    model.fit(train_x_arr, train_y_arr, epochs=epochs, shuffle=True, verbose=verbose)\n","\n","def eval_model(model, test_x_arr, test_y_arr):\n","    return model.evaluate(test_x_arr,  test_y_arr, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m8FoHZ9MfEry","scrolled":false,"outputId":"421f7468-2711-413c-d7e1-8b1857c675e0","executionInfo":{"status":"error","timestamp":1575612233534,"user_tz":480,"elapsed":36446,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = get_model()\n","print(train_y.shape)\n","print(train_x[0])\n","print(train_x.shape)\n","print(train_x.shape)\n","print(test_x.shape)\n","fit_model(model, train_x, train_y, epochs=10)\n","dev_loss, dev_acc = eval_model(model, dev_x, dev_y)\n","print('Development  set accuracy:', dev_acc)\n","test_loss, test_acc = eval_model(model, test_x, test_y)\n","print('Test  set accuracy:', test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","(76573, 1)\n","[[0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(76573, 160, 4)\n","(76573, 160, 4)\n","(23978, 160, 4)\n","Train on 76573 samples\n","Epoch 1/10\n","76573/76573 - 4s - loss: 0.8618 - acc: 0.6211\n","Epoch 2/10\n","76573/76573 - 4s - loss: 0.6923 - acc: 0.7210\n","Epoch 3/10\n","76573/76573 - 4s - loss: 0.5828 - acc: 0.7715\n","Epoch 4/10\n","76573/76573 - 4s - loss: 0.5034 - acc: 0.8076\n","Epoch 5/10\n","76573/76573 - 4s - loss: 0.4419 - acc: 0.8313\n","Epoch 6/10\n","76573/76573 - 4s - loss: 0.3901 - acc: 0.8534\n","Epoch 7/10\n","76573/76573 - 4s - loss: 0.3481 - acc: 0.8692\n","Epoch 8/10\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-9a75567798f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Development  set accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-54b1087a8685>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, train_x_arr, train_y_arr, verbose, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K45VoIYifHLB","scrolled":true,"colab":{}},"source":["predictions = model.predict(test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lE8S5xv8HiZA","colab_type":"text"},"source":["The code for plotting the image of our one-hot encoded sequence was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5SsYi7tIfHgV","scrolled":true,"colab":{}},"source":["def plot_image(i, predictions_array, true_label, img):\n","    \"\"\"\n","    Plots a sample image from our dataset.\n","    \"\"\"\n","    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    plt.imshow(img, cmap=plt.cm.binary)\n","\n","    predicted_label = np.argmax(predictions_array)\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","    print(true_label)\n","    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label[0]]),\n","                                color=color)\n","\n","i = 0\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(i, predictions[i], test_y, test_x)\n","plt.show()\n","print(predictions.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PYPxhP3ifO3U","scrolled":true,"colab":{}},"source":["plt.figure()\n","plt.imshow(train_x[0])\n","plt.grid(False)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4Xn2UHSHiZm","colab_type":"text"},"source":["The code for plotting the image of our one-hot encoded sequence was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"]},{"cell_type":"code","metadata":{"id":"c1wwwy8zHiZr","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(45,45))\n","range_to_show = 20\n","for i in range(range_to_show):\n","    plt.subplot(4, 5, i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    item_to_get = len(train_x) - i if int(i / 5) % 2 == 1 else i\n","    plt.imshow(train_x[item_to_get])\n","    plt.xlabel(class_names[train_y[item_to_get][0]])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5Z5G48UHiZ5","colab_type":"text"},"source":["## Regularization and Data Augmentation\n","\n","We now have a training accuracy of 99.3% and a test accuracy of 85.6%. We see that we have high variance and perhaps are overfitting our training set."]},{"cell_type":"code","metadata":{"id":"f64diiTtHiZ8","colab_type":"code","colab":{}},"source":["def get_hyperparameters(simple=False):\n","    \"\"\"\n","    :param simple: Whether or not to return only two hyperparameter configurations. For debugging.\n","    :return: Several hyperparamter configurations consisting of varying combinations of activation functions, hidden unit amounts, and l1 regularization constants.\n","    \"\"\"\n","    activations = [\"relu\", \"sigmoid\"]\n","    layer_vals = [8, 32, 64, 128]\n","    l1_vals = np.random.exponential(scale=0.015, size=(5,)).reshape(5, 1)\n","    hyperparameters_to_return = []\n","    print(l1_vals)\n","    if simple:\n","        return [{\n","                    'activation': activations[0], \n","                    'layer_val': 128,\n","                    'l1': 0.05\n","                },\n","                {\n","                    'activation': activations[1], \n","                    'layer_val': 128,\n","                    'l1': 0.05\n","                }]\n","\n","    for act in activations:\n","        for layer_val in layer_vals:\n","            for l_val in l1_vals:\n","                hyperparameters_to_return.append({\n","                    'activation': act, \n","                    'layer_val': layer_val,\n","                    'l1': l_val\n","                })\n","    return hyperparameters_to_return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"syDNYqCXHiaF","colab_type":"code","colab":{}},"source":["dev_accuracies = []\n","hyperparameters = get_hyperparameters(simple=False)\n","print(hyperparameters)\n","print(\"We are testing \" + str(len(hyperparameters)) + \".\")\n","for param in hyperparameters:\n","    print(param)\n","for hyper_params in hyperparameters:\n","    model_extended = get_model(l1_val=hyper_params['l1'],\n","                               middle_layer_val=hyper_params['layer_val'], \n","                               middle_layer_activation=hyper_params['activation'])\n","    fit_model(model_extended, \n","              train_x, \n","              train_y,\n","              verbose=0)\n","    dev_loss, dev_acc = eval_model(model_extended, dev_x, dev_y)\n","    dev_accuracies.append(dev_acc)\n","    print(dev_accuracies)\n","    print(hyper_params)\n","    print('Development set accuracy:', dev_acc)\n","\n","dev_accuracies = np.array(dev_accuracies)\n","print(dev_accuracies)\n","print(max(dev_accuracies))\n","index_of_hyper_to_get = dev_accuracies.argmax(axis=0)\n","print(hyperparameters[index_of_hyper_to_get])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DcOe4xeZHiaM","colab_type":"text"},"source":["None of these configurations resulted in an improved development set accuracy."]},{"cell_type":"markdown","metadata":{"id":"bTN0sPZhHiaN","colab_type":"text"},"source":["## CNN"]},{"cell_type":"markdown","metadata":{"id":"bkxkENxvHiaO","colab_type":"text"},"source":["The code for the CNN was adapted from the following source: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"]},{"cell_type":"code","metadata":{"id":"JOut87QdHiaQ","colab_type":"code","colab":{}},"source":["def create_model(input_shape, kernel_size=3):\n","    print(\"kernel size = \" + str(kernel_size))\n","    model_to_return = Sequential()\n","    convo_add = Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu', input_shape=(input_shape[1], input_shape[2], 1))\n","    model_to_return.add(convo_add)\n","    model_to_return.add(Conv2D(32, kernel_size=kernel_size, padding='same',activation='relu'))\n","    model_to_return.add(MaxPooling2D(pool_size=(2, 2)))\n","    \n","    model_to_return.add(Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'))\n","    model_to_return.add(Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'))\n","    model_to_return.add(MaxPooling2D(pool_size=(2, 2)))\n","    model_to_return.add(Dropout(0.25))\n","    \n","    model_to_return.add(Flatten())\n","    model_to_return.add(Dense(512, activation='relu'))\n","    model_to_return.add(Dropout(0.5))\n","    model_to_return.add(Dense(3, activation='softmax'))\n","    return model_to_return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7HyBX3hs6H0","colab_type":"code","outputId":"f5014300-003d-4148-e4e1-3296ce76978c","executionInfo":{"status":"ok","timestamp":1575610469239,"user_tz":480,"elapsed":1980,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_x_cnn, train_y_cnn = np.array(train_x), np.array(train_y)\n","print(train_x[0])\n","print(train_x_cnn.shape)\n","print(train_y_cnn.shape)\n","train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","model = create_model(train_x_cnn.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(76573, 160, 4)\n","(76573, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ILnyFNVVHiaV","colab_type":"code","outputId":"6ce0d7fe-d1d1-4f06-a5f8-db8076c028fa","executionInfo":{"status":"ok","timestamp":1575611001567,"user_tz":480,"elapsed":202401,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["fit_model(model, train_x_cnn, train_y_cnn, epochs=10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"," - 22s - loss: 0.3802 - acc: 0.8550\n","Epoch 2/10\n"," - 20s - loss: 0.3697 - acc: 0.8574\n","Epoch 3/10\n"," - 20s - loss: 0.3554 - acc: 0.8653\n","Epoch 4/10\n"," - 20s - loss: 0.3486 - acc: 0.8667\n","Epoch 5/10\n"," - 20s - loss: 0.3401 - acc: 0.8711\n","Epoch 6/10\n"," - 20s - loss: 0.3288 - acc: 0.8738\n","Epoch 7/10\n"," - 20s - loss: 0.3255 - acc: 0.8770\n","Epoch 8/10\n"," - 20s - loss: 0.3138 - acc: 0.8808\n","Epoch 9/10\n"," - 20s - loss: 0.3091 - acc: 0.8832\n","Epoch 10/10\n"," - 20s - loss: 0.3078 - acc: 0.8831\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CyNPuZxjHiad","colab_type":"code","outputId":"d1f788ce-959a-4035-96f5-0803033aa88d","executionInfo":{"status":"ok","timestamp":1575611089555,"user_tz":480,"elapsed":4771,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n","print('Development set accuracy:', dev_acc)\n","\n","test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","test_loss, test_acc = eval_model(model, test_x_cnn, test_y)\n","print('Test set accuracy:', test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Development set accuracy: 0.817085020175347\n","Test set accuracy: 0.8234214696805405\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B3_Zk1eCHiaj","colab_type":"text"},"source":["#### The visualization for the classes was adapted from the following source: https://jacobgil.github.io/deeplearning/class-activation-maps"]},{"cell_type":"code","metadata":{"id":"uE8CqZJRHiak","colab_type":"code","colab":{}},"source":["def visualize_class_activation_map():\n","    original_img = dev_x_cnn[0]\n","    width, height, _ = original_img.shape # original_img.shape\n","    \n","    img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n","    \n","    class_weights = model.layers[-1].get_weights()[0]\n","    \n","    get_output = K.function([model.layers[0].input], \\\n","                [model.layers[len(model.layers) - 1].output, \n","    model.layers[-1].output])\n","    [conv_outputs, predictions] = get_output([img])\n","    conv_outputs = conv_outputs[0, :, :, :]\n","\n","    # Class activation map.\n","    cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n","    target_class = 1\n","    for i, w in enumerate(class_weights[:, target_class]):\n","            cam += w * conv_outputs[i, :, :]\n","\n","model.summary()\n","\n","layer_outputs = [layer.output for layer in model.layers[:12]]\n","\n","from keras import models\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","\n","img_tensor = np.expand_dims(dev_x_cnn[10], axis=0)\n","img_tensor = img_tensor / 255\n","img_tensor_to_show = img_tensor[0,:,:,0:1].reshape(160,4)\n","print(img_tensor_to_show.shape)\n","plt.imshow(img_tensor_to_show)\n","plt.show()\n","\n","activations = activation_model.predict(img_tensor) \n","first_layer_activation = activations[0]\n","print(first_layer_activation.shape)\n","plt.matshow(first_layer_activation[0, :, :, 32], cmap='viridis')\n","\n","DEBUG = False\n","\n","if DEBUG:\n","    last_layer_act = activations[3]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[:, :], cmap='viridis')\n","    \n","    last_layer_act = activations[1]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[0, :, :, 1], cmap='viridis')\n","\n","    last_layer_act = activations[len(activations) - 2]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[:], cmap='viridis')\n","\n","\n","    last_layer_act = activations[len(activations) - 1]\n","    print(last_layer_act.shape)\n","    plt.matshow(last_layer_act[:], cmap='viridis')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hoxr6hskHiap","colab_type":"code","colab":{}},"source":["model = create_model(train_x_cnn.shape)\n","fit_model(model, train_x_cnn, train_y_cnn, epochs=100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yC54MYkvHiau","colab_type":"code","colab":{}},"source":["dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n","print('Development set accuracy:', dev_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqUahBsbujzt","colab_type":"code","outputId":"00311161-a447-42ba-e311-674e4235ff3b","executionInfo":{"status":"ok","timestamp":1575626327210,"user_tz":480,"elapsed":31165,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# This represents our second round of hyperparameter testing\n","\n","def hyperparameter_testing():\n","  print(\"set 1\")\n","  print(\"center padding\")\n","  cnn_epochs = []\n","  nn_epochs = [5]\n","  tests = [\n","           [\"cnn\", 3],\n","           [\"cnn\", 4],\n","           [\"nn\", None],\n","          ]\n","  print(train_x[0])\n","  results = []\n","  for test in tests:\n","    if test[0] == \"nn\":\n","      result = []\n","      for epoch in nn_epochs:\n","        model = get_model()\n","        fit_model(model, train_x, train_y, epochs=epoch)\n","        train_loss, train_acc = eval_model(model, train_x, train_y)\n","        dev_loss, dev_acc = eval_model(model, dev_x, dev_y)\n","        print('Development  set accuracy:', dev_acc)\n","        test_loss, test_acc = eval_model(model, test_x, test_y)\n","        print('Test  set accuracy:', test_acc)\n","        result.append([train_acc, dev_acc, test_acc])\n","      results.append(result)\n","    else:\n","      result = []\n","      \n","\n","      for epoch in cnn_epochs:\n","        \n","        train_x_cnn, train_y_cnn = np.array(train_x), np.array(train_y)\n","\n","        kernel_size = test[1]\n","        model = create_model(train_x_cnn.shape, kernel_size=kernel_size)\n","\n","        print(train_x[0])\n","        print(train_x_cnn.shape)\n","        print(train_y_cnn.shape)\n","        train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","\n","        fit_model(model, train_x_cnn, train_y_cnn, epochs=epoch)\n","\n","        train_loss, train_acc = eval_model(model, train_x_cnn, train_y_cnn)\n","\n","        dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","\n","        dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n","        print('Development set accuracy:', dev_acc)\n","\n","        test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","\n","        test_loss, test_acc = eval_model(model, test_x_cnn, test_y)\n","        print('Test set accuracy:', test_acc)\n","        result.append([train_acc, dev_acc, test_acc])\n","      results.append(result)\n","  return results\n","\n","results = hyperparameter_testing()\n","print(results)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["set 1\n","center padding\n","[[0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","Train on 76573 samples\n","Epoch 1/5\n","76573/76573 - 5s - loss: 0.8978 - acc: 0.5954\n","Epoch 2/5\n","76573/76573 - 4s - loss: 0.7487 - acc: 0.6864\n","Epoch 3/5\n","76573/76573 - 5s - loss: 0.6349 - acc: 0.7459\n","Epoch 4/5\n","76573/76573 - 4s - loss: 0.5494 - acc: 0.7864\n","Epoch 5/5\n","76573/76573 - 5s - loss: 0.4862 - acc: 0.8121\n","Development  set accuracy: 0.68898785\n","Test  set accuracy: 0.6877971\n","[[], [], [[0.86735535, 0.68898785, 0.6877971]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n_0yHmRLxSen","colab_type":"code","outputId":"838dc2b5-d542-49cc-c38c-df33269c9087","executionInfo":{"status":"ok","timestamp":1575629137744,"user_tz":480,"elapsed":407603,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_x_cnn, train_y_cnn = np.array(train_x), np.array(train_y)\n","\n","best_model = create_model(train_x_cnn.shape, kernel_size=3)\n","\n","print(train_x[0])\n","print(train_x_cnn.shape)\n","print(train_y_cnn.shape)\n","train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","\n","fit_model(best_model, train_x_cnn, train_y_cnn, epochs=25)\n","\n","train_loss, train_acc = eval_model(best_model, train_x_cnn, train_y_cnn)\n","\n","dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n","\n","dev_loss, dev_acc = eval_model(best_model, dev_x_cnn, dev_y)\n","print('Development set accuracy:', dev_acc)\n","\n","test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","\n","test_loss, test_acc = eval_model(best_model, test_x_cnn, test_y)\n","print('Test set accuracy:', test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 0 1 0]\n"," [0 0 1 0]\n"," [0 0 0 1]\n"," [0 1 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [0 0 1 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]\n"," [0 0 0 0]]\n","(60501, 160, 4)\n","(60501, 1)\n","Epoch 1/25\n"," - 18s - loss: 0.7213 - acc: 0.7174\n","Epoch 2/25\n"," - 16s - loss: 0.6085 - acc: 0.7608\n","Epoch 3/25\n"," - 16s - loss: 0.5345 - acc: 0.7953\n","Epoch 4/25\n"," - 16s - loss: 0.4790 - acc: 0.8190\n","Epoch 5/25\n"," - 16s - loss: 0.4341 - acc: 0.8363\n","Epoch 6/25\n"," - 16s - loss: 0.3944 - acc: 0.8526\n","Epoch 7/25\n"," - 16s - loss: 0.3572 - acc: 0.8670\n","Epoch 8/25\n"," - 16s - loss: 0.3329 - acc: 0.8756\n","Epoch 9/25\n"," - 16s - loss: 0.3106 - acc: 0.8861\n","Epoch 10/25\n"," - 16s - loss: 0.2870 - acc: 0.8930\n","Epoch 11/25\n"," - 16s - loss: 0.2730 - acc: 0.8984\n","Epoch 12/25\n"," - 16s - loss: 0.2588 - acc: 0.9044\n","Epoch 13/25\n"," - 16s - loss: 0.2439 - acc: 0.9092\n","Epoch 14/25\n"," - 16s - loss: 0.2354 - acc: 0.9121\n","Epoch 15/25\n"," - 16s - loss: 0.2239 - acc: 0.9171\n","Epoch 16/25\n"," - 16s - loss: 0.2162 - acc: 0.9199\n","Epoch 17/25\n"," - 16s - loss: 0.2082 - acc: 0.9217\n","Epoch 18/25\n"," - 16s - loss: 0.1991 - acc: 0.9271\n","Epoch 19/25\n"," - 16s - loss: 0.1936 - acc: 0.9293\n","Epoch 20/25\n"," - 16s - loss: 0.1881 - acc: 0.9303\n","Epoch 21/25\n"," - 16s - loss: 0.1835 - acc: 0.9320\n","Epoch 22/25\n"," - 16s - loss: 0.1790 - acc: 0.9350\n","Epoch 23/25\n"," - 16s - loss: 0.1743 - acc: 0.9362\n","Epoch 24/25\n"," - 16s - loss: 0.1714 - acc: 0.9378\n","Epoch 25/25\n"," - 16s - loss: 0.1652 - acc: 0.9401\n","Development set accuracy: 0.8975289965301105\n","Test set accuracy: 0.8915166310468097\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ng4MXfjNyi55","colab_type":"code","outputId":"5474e933-7edf-455e-bd95-c8964478ad5f","executionInfo":{"status":"ok","timestamp":1575629139203,"user_tz":480,"elapsed":1431,"user":{"displayName":"Josh Wolff","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64","userId":"15643205438540806758"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"source":["best_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_61 (Conv2D)           (None, 160, 4, 64)        640       \n","_________________________________________________________________\n","conv2d_62 (Conv2D)           (None, 160, 4, 32)        18464     \n","_________________________________________________________________\n","max_pooling2d_31 (MaxPooling (None, 80, 2, 32)         0         \n","_________________________________________________________________\n","conv2d_63 (Conv2D)           (None, 80, 2, 64)         18496     \n","_________________________________________________________________\n","conv2d_64 (Conv2D)           (None, 80, 2, 64)         36928     \n","_________________________________________________________________\n","max_pooling2d_32 (MaxPooling (None, 40, 1, 64)         0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 40, 1, 64)         0         \n","_________________________________________________________________\n","flatten_16 (Flatten)         (None, 2560)              0         \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 512)               1311232   \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_32 (Dense)             (None, 3)                 1539      \n","=================================================================\n","Total params: 1,387,299\n","Trainable params: 1,387,299\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9oeDb-X1yn-y","colab_type":"code","colab":{}},"source":["best_model.save(\"triple.h5\")\n","from google.colab import files\n","files.download('triple.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_77rGV9S1y6L","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}