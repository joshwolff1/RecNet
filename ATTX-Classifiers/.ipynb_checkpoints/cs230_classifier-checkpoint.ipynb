{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 946
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1397,
     "status": "error",
     "timestamp": 1571631719569,
     "user": {
      "displayName": "Josh Wolff",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64",
      "userId": "15643205438540806758"
     },
     "user_tz": 420
    },
    "id": "b5nsm_F4eZex",
    "outputId": "217683e7-f5b5-49bb-caf5-bc2a6393a93d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYnMMd-qefwi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = [\"attB\", \"attP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell for the following functions was adapted from our RNN implementation: load_data(...), pad_zeros(...), get_y(...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 998
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 270,
     "status": "error",
     "timestamp": 1571631704466,
     "user": {
      "displayName": "Josh Wolff",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBE4pikTRqVXi5rWqD4WPEwwXT47Sfoari0--GnFeg=s64",
      "userId": "15643205438540806758"
     },
     "user_tz": 420
    },
    "id": "8K70f7dUlwgD",
    "outputId": "ee9b14aa-f6b0-4646-c034-3aa802aac27b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20301\n",
      "20301\n",
      "40602\n",
      "(40602, 1)\n",
      "(40602, 160, 4)\n",
      "(40602, 160, 4)\n",
      "(11404, 160, 4)\n"
     ]
    }
   ],
   "source": [
    "char2index = {'A':[1, 0, 0, 0], 'C':[0, 1, 0, 0], 'G':[0, 0, 1, 0], 'T':[0, 0, 0, 1]}\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    X = [[char2index[char] for char in seq] for seq in df.attb]\n",
    "    Y = [[char2index[char] for char in seq] for seq in df.attp]\n",
    "    return X, Y\n",
    "\n",
    "train_attb, train_attp = load_data('set1/attB2attP/train.tsv')\n",
    "dev_attb, dev_attp = load_data('set1/attB2attP/dev.tsv')\n",
    "test_attb, test_attp = load_data('set1/attB2attP/test.tsv')\n",
    "\n",
    "def pad_zeros(data, max_pad=160, centered_pad=False):\n",
    "    padded_data = []\n",
    "    for row in data:\n",
    "        if max_pad - len(row) > 0:\n",
    "            if centered_pad:\n",
    "                diff = max_pad - len(row)\n",
    "                left_val = int(diff / 2)\n",
    "                right_val = int(diff / 2) + int(diff % 2)\n",
    "                row = [[0, 0, 0, 0]]*left_val + row + [[0, 0, 0, 0]]*right_val\n",
    "            else:\n",
    "                row = row + [[0, 0, 0, 0]]*(max_pad - len(row))\n",
    "        padded_data.append(row)\n",
    "    return np.array(padded_data)\n",
    "\n",
    "\n",
    "def get_y(attb, attp):\n",
    "    y_to_return = np.array(len(attb) * [0] + len(attp) * [1])\n",
    "    return y_to_return.reshape(y_to_return.shape[0], 1)\n",
    "\n",
    "print(len(train_attb))\n",
    "print(len(train_attp))\n",
    "print(len(train_attb + train_attp))\n",
    "train_x = train_attb + train_attp\n",
    "dev_x = dev_attb + dev_attp\n",
    "test_x = test_attb + test_attp\n",
    "\n",
    "\n",
    "train_x, train_y = pad_zeros(train_x), get_y(train_attb, train_attp)\n",
    "dev_x, dev_y = pad_zeros(dev_x), get_y(dev_attb, dev_attp)\n",
    "test_x, test_y = pad_zeros(test_x), get_y(test_attb, test_attp)\n",
    "\n",
    "train_x = pad_zeros(train_x)\n",
    "dev_x = pad_zeros(dev_x)\n",
    "test_x = pad_zeros(test_x)\n",
    "\n",
    "print(train_y.shape)\n",
    "print(train_x.shape)\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this model was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKIpFEKOe2Nr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_model(l1_val=None, middle_layer_val=128, middle_layer_activation=\"relu\"):\n",
    "    model_to_return = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(160, 4))\n",
    "    ])\n",
    "    if l1_val is not None:\n",
    "        model_to_return.add(keras.layers.Dense(middle_layer_val, input_dim=160,\n",
    "                                               activation=middle_layer_activation,\n",
    "                                               activity_regularizer=regularizers.l1(l1_val)))\n",
    "    else:\n",
    "        model_to_return.add(keras.layers.Dense(middle_layer_val, activation=middle_layer_activation))\n",
    "\n",
    "    model_to_return.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    return model_to_return\n",
    "\n",
    "def fit_model(model, train_x_arr, train_y_arr, verbose=2, epochs=25):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_x_arr, train_y_arr, epochs=epochs, shuffle=True, verbose=verbose)\n",
    "\n",
    "def eval_model(model, test_x_arr, test_y_arr):\n",
    "    return model.evaluate(test_x_arr,  test_y_arr, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8FoHZ9MfEry",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40602 samples\n",
      "Epoch 1/25\n",
      "40602/40602 - 2s - loss: 0.4960 - acc: 0.7538\n",
      "Epoch 2/25\n",
      "40602/40602 - 1s - loss: 0.3293 - acc: 0.8533\n",
      "Epoch 3/25\n",
      "40602/40602 - 1s - loss: 0.2222 - acc: 0.9100\n",
      "Epoch 4/25\n",
      "40602/40602 - 1s - loss: 0.1466 - acc: 0.9464\n",
      "Epoch 5/25\n",
      "40602/40602 - 1s - loss: 0.0907 - acc: 0.9705\n",
      "Epoch 6/25\n",
      "40602/40602 - 1s - loss: 0.0605 - acc: 0.9829\n",
      "Epoch 7/25\n",
      "40602/40602 - 1s - loss: 0.0426 - acc: 0.9890\n",
      "Epoch 8/25\n",
      "40602/40602 - 2s - loss: 0.0329 - acc: 0.9917\n",
      "Epoch 9/25\n",
      "40602/40602 - 2s - loss: 0.0316 - acc: 0.9915\n",
      "Epoch 10/25\n",
      "40602/40602 - 2s - loss: 0.0285 - acc: 0.9926\n",
      "Epoch 11/25\n",
      "40602/40602 - 2s - loss: 0.0241 - acc: 0.9936\n",
      "Epoch 12/25\n",
      "40602/40602 - 2s - loss: 0.0236 - acc: 0.9936\n",
      "Epoch 13/25\n",
      "40602/40602 - 2s - loss: 0.0241 - acc: 0.9935\n",
      "Epoch 14/25\n",
      "40602/40602 - 2s - loss: 0.0179 - acc: 0.9956\n",
      "Epoch 15/25\n",
      "40602/40602 - 2s - loss: 0.0200 - acc: 0.9943\n",
      "Epoch 16/25\n",
      "40602/40602 - 2s - loss: 0.0185 - acc: 0.9943\n",
      "Epoch 17/25\n",
      "40602/40602 - 2s - loss: 0.0197 - acc: 0.9943\n",
      "Epoch 18/25\n",
      "40602/40602 - 2s - loss: 0.0182 - acc: 0.9950\n",
      "Epoch 19/25\n",
      "40602/40602 - 2s - loss: 0.0155 - acc: 0.9961\n",
      "Epoch 20/25\n",
      "40602/40602 - 2s - loss: 0.0177 - acc: 0.9946\n",
      "Epoch 21/25\n",
      "40602/40602 - 2s - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 22/25\n",
      "40602/40602 - 2s - loss: 0.0144 - acc: 0.9960\n",
      "Epoch 23/25\n",
      "40602/40602 - 2s - loss: 0.0170 - acc: 0.9952\n",
      "Epoch 24/25\n",
      "40602/40602 - 2s - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 25/25\n",
      "40602/40602 - 2s - loss: 0.0132 - acc: 0.9962\n",
      "Development  set accuracy: 0.8394978\n",
      "Test  set accuracy: 0.8481235\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "fit_model(model, train_x, train_y)\n",
    "dev_loss, dev_acc = eval_model(model, dev_x, dev_y)\n",
    "print('Development  set accuracy:', dev_acc)\n",
    "test_loss, test_acc = eval_model(model, test_x, test_y)\n",
    "print('Test  set accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K45VoIYifHLB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for plotting the image of our one-hot encoded sequence was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SsYi7tIfHgV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    \"\"\"\n",
    "    Plots a sample image from our dataset.\n",
    "    \"\"\"\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    print(true_label)\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label[0]]),\n",
    "                                color=color)\n",
    "\n",
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_y, test_x)\n",
    "plt.show()\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYPxhP3ifO3U",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_x[0])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for plotting the image of our one-hot encoded sequence was adapted from the following source: https://www.tensorflow.org/tutorials/keras/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45,45))\n",
    "range_to_show = 20\n",
    "for i in range(range_to_show):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    item_to_get = len(train_x) - i if int(i / 5) % 2 == 1 else i\n",
    "    plt.imshow(train_x[item_to_get])\n",
    "    plt.xlabel(class_names[train_y[item_to_get][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization and Data Augmentation\n",
    "\n",
    "We now have a training accuracy of 99.3% and a test accuracy of 85.6%. We see that we have high variance and perhaps are overfitting our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparameters(simple=False):\n",
    "    \"\"\"\n",
    "    :param simple: Whether or not to return only two hyperparameter configurations. For debugging.\n",
    "    :return: Several hyperparamter configurations consisting of varying combinations of activation functions, hidden unit amounts, and l1 regularization constants.\n",
    "    \"\"\"\n",
    "    activations = [\"relu\", \"sigmoid\"]\n",
    "    layer_vals = [8, 32, 64, 128]\n",
    "    l1_vals = np.random.exponential(scale=0.015, size=(5,)).reshape(5, 1)\n",
    "    hyperparameters_to_return = []\n",
    "    print(l1_vals)\n",
    "    if simple:\n",
    "        return [{\n",
    "                    'activation': activations[0], \n",
    "                    'layer_val': 128,\n",
    "                    'l1': 0.05\n",
    "                },\n",
    "                {\n",
    "                    'activation': activations[1], \n",
    "                    'layer_val': 128,\n",
    "                    'l1': 0.05\n",
    "                }]\n",
    "\n",
    "    for act in activations:\n",
    "        for layer_val in layer_vals:\n",
    "            for l_val in l1_vals:\n",
    "                hyperparameters_to_return.append({\n",
    "                    'activation': act, \n",
    "                    'layer_val': layer_val,\n",
    "                    'l1': l_val\n",
    "                })\n",
    "    return hyperparameters_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_accuracies = []\n",
    "hyperparameters = get_hyperparameters(simple=False)\n",
    "print(hyperparameters)\n",
    "print(\"We are testing \" + str(len(hyperparameters)) + \".\")\n",
    "for param in hyperparameters:\n",
    "    print(param)\n",
    "for hyper_params in hyperparameters:\n",
    "    model_extended = get_model(l1_val=hyper_params['l1'],\n",
    "                               middle_layer_val=hyper_params['layer_val'], \n",
    "                               middle_layer_activation=hyper_params['activation'])\n",
    "    fit_model(model_extended, \n",
    "              train_x, \n",
    "              train_y,\n",
    "              verbose=0)\n",
    "    dev_loss, dev_acc = eval_model(model_extended, dev_x, dev_y)\n",
    "    dev_accuracies.append(dev_acc)\n",
    "    print(dev_accuracies)\n",
    "    print(hyper_params)\n",
    "    print('Development set accuracy:', dev_acc)\n",
    "\n",
    "dev_accuracies = np.array(dev_accuracies)\n",
    "print(dev_accuracies)\n",
    "print(max(dev_accuracies))\n",
    "index_of_hyper_to_get = dev_accuracies.argmax(axis=0)\n",
    "print(hyperparameters[index_of_hyper_to_get])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these configurations resulted in an improved development set accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the CNN was adapted from the following source: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    kernel_size = 4\n",
    "    \n",
    "    model_to_return = Sequential()\n",
    "    convo_add = Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu', input_shape=(input_shape[1], input_shape[2], 1))\n",
    "    model_to_return.add(convo_add)\n",
    "    model_to_return.add(Conv2D(32, kernel_size=kernel_size, padding='same',activation='relu'))\n",
    "    model_to_return.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model_to_return.add(Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'))\n",
    "    model_to_return.add(Conv2D(64, kernel_size=kernel_size, padding='same', activation='relu'))\n",
    "    model_to_return.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_to_return.add(Dropout(0.25))\n",
    "    \n",
    "    model_to_return.add(Flatten())\n",
    "    model_to_return.add(Dense(512, activation='relu'))\n",
    "    model_to_return.add(Dropout(0.5))\n",
    "    model_to_return.add(Dense(2, activation='softmax'))\n",
    "    return model_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40602, 160, 4)\n",
      "(40602, 1)\n",
      "Epoch 1/25\n",
      "165s - loss: 0.5509 - acc: 0.7150\n",
      "Epoch 2/25\n",
      "171s - loss: 0.4486 - acc: 0.7877\n",
      "Epoch 3/25\n",
      "170s - loss: 0.3851 - acc: 0.8212\n",
      "Epoch 4/25\n",
      "187s - loss: 0.3340 - acc: 0.8479\n",
      "Epoch 5/25\n",
      "195s - loss: 0.2923 - acc: 0.8701\n",
      "Epoch 6/25\n",
      "202s - loss: 0.2594 - acc: 0.8868\n",
      "Epoch 7/25\n",
      "212s - loss: 0.2287 - acc: 0.9006\n",
      "Epoch 8/25\n",
      "218s - loss: 0.2061 - acc: 0.9112\n",
      "Epoch 9/25\n",
      "214s - loss: 0.1895 - acc: 0.9181\n",
      "Epoch 10/25\n",
      "236s - loss: 0.1694 - acc: 0.9297\n",
      "Epoch 11/25\n",
      "223s - loss: 0.1560 - acc: 0.9352\n",
      "Epoch 12/25\n",
      "209s - loss: 0.1441 - acc: 0.9420\n",
      "Epoch 13/25\n",
      "207s - loss: 0.1391 - acc: 0.9432\n",
      "Epoch 14/25\n",
      "208s - loss: 0.1270 - acc: 0.9493\n",
      "Epoch 15/25\n",
      "247s - loss: 0.1218 - acc: 0.9521\n",
      "Epoch 16/25\n",
      "290s - loss: 0.1153 - acc: 0.9544\n",
      "Epoch 17/25\n",
      "233s - loss: 0.1126 - acc: 0.9557\n",
      "Epoch 18/25\n",
      "216s - loss: 0.1057 - acc: 0.9588\n",
      "Epoch 19/25\n",
      "211s - loss: 0.1015 - acc: 0.9608\n",
      "Epoch 20/25\n",
      "226s - loss: 0.1001 - acc: 0.9612\n",
      "Epoch 21/25\n",
      "199s - loss: 0.0973 - acc: 0.9631\n",
      "Epoch 22/25\n",
      "229s - loss: 0.0901 - acc: 0.9650\n",
      "Epoch 23/25\n",
      "246s - loss: 0.0942 - acc: 0.9640\n",
      "Epoch 24/25\n",
      "250s - loss: 0.0862 - acc: 0.9670\n",
      "Epoch 25/25\n",
      "223s - loss: 0.0858 - acc: 0.9682\n"
     ]
    }
   ],
   "source": [
    "train_x_cnn, train_y_cnn = np.array(train_x), np.array(train_y)\n",
    "print(train_x_cnn.shape)\n",
    "print(train_y_cnn.shape)\n",
    "train_x_cnn = train_x_cnn.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n",
    "model = create_model(train_x_cnn.shape)\n",
    "fit_model(model, train_x_cnn, train_y_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development set accuracy: 0.8749575839634867\n",
      "Test set accuracy: 0.8793405822309349\n"
     ]
    }
   ],
   "source": [
    "dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n",
    "dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n",
    "print('Development set accuracy:', dev_acc)\n",
    "\n",
    "test_x_cnn = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n",
    "test_loss, test_acc = eval_model(model, test_x_cnn, test_y)\n",
    "print('Test set accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization for the classes was adapted from the following source: https://jacobgil.github.io/deeplearning/class-activation-maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_class_activation_map():\n",
    "    original_img = dev_x_cnn[0]\n",
    "    width, height, _ = original_img.shape # original_img.shape\n",
    "    \n",
    "    img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
    "    \n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    \n",
    "    get_output = K.function([model.layers[0].input], \\\n",
    "                [model.layers[len(model.layers) - 1].output, \n",
    "    model.layers[-1].output])\n",
    "    [conv_outputs, predictions] = get_output([img])\n",
    "    conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "    # Class activation map.\n",
    "    cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
    "    target_class = 1\n",
    "    for i, w in enumerate(class_weights[:, target_class]):\n",
    "            cam += w * conv_outputs[i, :, :]\n",
    "\n",
    "model.summary()\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers[:12]]\n",
    "\n",
    "from keras import models\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "img_tensor = np.expand_dims(dev_x_cnn[10], axis=0)\n",
    "img_tensor = img_tensor / 255\n",
    "img_tensor_to_show = img_tensor[0,:,:,0:1].reshape(160,4)\n",
    "print(img_tensor_to_show.shape)\n",
    "plt.imshow(img_tensor_to_show)\n",
    "plt.show()\n",
    "\n",
    "activations = activation_model.predict(img_tensor) \n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "plt.matshow(first_layer_activation[0, :, :, 32], cmap='viridis')\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    last_layer_act = activations[3]\n",
    "    print(last_layer_act.shape)\n",
    "    plt.matshow(last_layer_act[:, :], cmap='viridis')\n",
    "    \n",
    "    last_layer_act = activations[1]\n",
    "    print(last_layer_act.shape)\n",
    "    plt.matshow(last_layer_act[0, :, :, 1], cmap='viridis')\n",
    "\n",
    "    last_layer_act = activations[len(activations) - 2]\n",
    "    print(last_layer_act.shape)\n",
    "    plt.matshow(last_layer_act[:], cmap='viridis')\n",
    "\n",
    "\n",
    "    last_layer_act = activations[len(activations) - 1]\n",
    "    print(last_layer_act.shape)\n",
    "    plt.matshow(last_layer_act[:], cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(train_x_cnn.shape)\n",
    "fit_model(model, train_x_cnn, train_y_cnn, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x_cnn = dev_x.reshape(dev_x.shape[0], dev_x.shape[1], dev_x.shape[2], 1)\n",
    "dev_loss, dev_acc = eval_model(model, dev_x_cnn, dev_y)\n",
    "print('Development set accuracy:', dev_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cs230_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
